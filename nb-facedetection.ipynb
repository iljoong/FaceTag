{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application - Face detection\n",
    "\n",
    "References:\n",
    "\n",
    "- https://towardsdatascience.com/face-detection-for-beginners-e58e8f21aad9\n",
    "- https://towardsdatascience.com/cnn-based-face-detector-from-dlib-c3696195e01c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "import dlib\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade = cv2.CascadeClassifier('./face/haarcascade_frontalface_default.xml')\n",
    "eyeCascade = cv2.CascadeClassifier('./face/haarcascade_eye.xml')\n",
    "\n",
    "def detectFaceCV(gray):\n",
    "\n",
    "    start_time = time.time()\n",
    "    faces = []\n",
    "    try:\n",
    "        #gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #gray = cv2.equalizeHist(gray)\n",
    "        rects = cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=4, minSize=(30, 30),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        \n",
    "        for rect in rects:\n",
    "            (x, y, w, h) = rect\n",
    "            roi = gray[y:y+h, x:x+w]\n",
    "            faces.append(rect)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return faces, time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectFaceEyeCV(gray):\n",
    "\n",
    "    start_time = time.time()\n",
    "    faces = []\n",
    "    try:\n",
    "        rects = cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=4, minSize=(30, 30),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        \n",
    "        for rect in rects:\n",
    "            (x, y, w, h) = rect\n",
    "            roi = gray[y:y+h, x:x+w]\n",
    "            eyes = eyeCascade.detectMultiScale(roi)\n",
    "            if len(eyes):\n",
    "                faces.append(rect)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return faces, time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "def detectFaceHog(gray):\n",
    "    \n",
    "    start_time = time.time()   \n",
    "    rects = []\n",
    "    try:\n",
    "        rects = hog_face_detector(gray, 1)\n",
    "        \n",
    "        faces = [ [rect.left(), rect.top(), rect.right()-rect.left(), rect.bottom()-rect.top()] for rect in rects ]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return faces, time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING: too slow to detect in realtime with CPU\n",
    "cnn_face_detector = dlib.cnn_face_detection_model_v1(\"./face/mmod_human_face_detector.dat\")\n",
    "\n",
    "def detectFaceCNN(gray):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    rects = []\n",
    "    try:\n",
    "        rects = cnn_face_detector(gray, 1)\n",
    "        \n",
    "        faces = [ [rect.rect.left(), rect.rect.top(), rect.rect.right()-rect.rect.left(), rect.rect.bottom()-rect.rect.top()] for rect in rects ]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return faces, time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize size of image width\n",
    "_resize = 640 #1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect with reduced size\n",
    "def displayface(img, detectfn=detectFaceCV):\n",
    "       \n",
    "    # resize image\n",
    "    imgh, imgw, imgc = img.shape\n",
    "    scale = 1.0\n",
    "    if (imgh > _resize  or imgw > _resize ):\n",
    "        scale = imgh if (imgh > imgw) else imgw\n",
    "        scale = _resize / scale\n",
    "\n",
    "    img = cv2.resize(img, (int(imgw*scale), int(imgh*scale)), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    # detect\n",
    "    faces, _ = detectfn(img)\n",
    "\n",
    "    numface = len(faces)\n",
    "    for face in faces:\n",
    "        print(face)\n",
    "        (x, y, w, h) = face\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            \n",
    "    imgdetect = Image.fromarray(img)\n",
    "    display(imgdetect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare each detection algorithm\n",
    "def detectcompare(img):\n",
    "       \n",
    "    # resize image\n",
    "    imgh, imgw, imgc = img.shape\n",
    "    scale = 1.0\n",
    "    if (imgh > _resize  or imgw > _resize ):\n",
    "        scale = imgh if (imgh > imgw) else imgw\n",
    "        scale = _resize / scale\n",
    "\n",
    "    img = cv2.resize(img, (int(imgw*scale), int(imgh*scale)), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    # detect\n",
    "    faces1, t1 = detectFaceCV(img)\n",
    "    faces2, t2 = detectFaceHog(img)\n",
    "    faces3, t3 = detectFaceCNN(img)\n",
    "\n",
    "    for face in faces1:\n",
    "        (x, y, w, h) = face\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "\n",
    "    for face in faces2:\n",
    "        (x, y, w, h) = face\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "    for face in faces3:\n",
    "        (x, y, w, h) = face\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "        \n",
    "    imgdetect = Image.fromarray(img)\n",
    "    display(imgdetect)\n",
    "    \n",
    "    print(\"cv(red): {:.2f} sec, hog(green): {:.2f} sec, cnn(blue): {:.2f} sec\".format(t1, t2, t3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test samples\n",
    "test_urls = [ 'http://www.science-alive.co.uk/wp-content/uploads/2012/04/Young-people.jpg' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_url in test_urls:\n",
    "    r = requests.get(test_url)\n",
    "    img = Image.open(BytesIO(r.content))\n",
    "    img = np.array(img)\n",
    "    \n",
    "    displayface(img, detectFaceCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for test_url in test_urls:\n",
    "    r = requests.get(test_url)\n",
    "    img = Image.open(BytesIO(r.content))\n",
    "    img = np.array(img)\n",
    "    \n",
    "    detectcompare(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live Detection (Camera capture)\n",
    "\n",
    "__Note__: run this on local PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "print('width: {}, height: {}'.format(cap.get(3),cap.get(4)))\n",
    "cap.set(3,320)\n",
    "cap.set(4,240)\n",
    "\n",
    "ts, f, i = time.time(), 0, 0;\n",
    "x, y, w, h = 0, 0, 0, 0\n",
    "dt = time.time()\n",
    "while(True):\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if (ret):\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        rects, _ = detectFaceEyeCV(gray)\n",
    "        #rects, _ = detectFaceHog(gray)\n",
    "               \n",
    "        for rect in rects:\n",
    "            (x, y, w, h) = rect\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        \n",
    "        ### keep preview detection region - for multiple faces?\n",
    "        #dt = time.time() if len(rects) else dt\n",
    "        #if (time.time() - dt < 1.0):\n",
    "        #    cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            \n",
    "        te = time.time()\n",
    "        i += 1\n",
    "        if (te - ts > 1.0):\n",
    "            ts = te\n",
    "            f = i\n",
    "            i = 0\n",
    "            \n",
    "        cv2.putText(frame, \"{}fps\".format(f), (10,40), 2, 0.7, (255, 0, 0))        \n",
    "        cv2.imshow('frame', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

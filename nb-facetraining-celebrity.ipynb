{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition(Classification) using Keras\n",
    "\n",
    "Detect and classify using Keras\n",
    "\n",
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, InputLayer, Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras import backend as K\n",
    "import keras\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare Data\n",
    "\n",
    "download datasets from https://www.kaggle.com/dansbecker/5-celebrity-faces-dataset and save them right directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 200, 200\n",
    "train_data_dir = '../datasets/celebrity/train'\n",
    "validation_data_dir = '../datasets/celebrity/val'\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range = 0.1, # Randomly zoom image \n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    #shear_range=0.2,\n",
    "    vertical_flip=False,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = 93\n",
    "nb_validation_samples = 25\n",
    "epochs = 20\n",
    "numclasses = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16CNNtl(input_shape, outclass, sigma='sigmoid'):\n",
    "    \n",
    "    base_model = None\n",
    "    base_model = keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "    for i in range(2):\n",
    "        top_model.add(Dense(4096, activation='relu'))\n",
    "        top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(outclass, activation=sigma))\n",
    "\n",
    "    model = None\n",
    "    model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
    "    \n",
    "    return model\n",
    " \n",
    "def resnet50tl(input_shape, outclass, sigma='sigmoid'):\n",
    "    \n",
    "    base_model = None\n",
    "    base_model = keras.applications.resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "    for i in range(2):\n",
    "        top_model.add(Dense(4096, activation='relu'))\n",
    "        top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(outclass, activation=sigma))\n",
    "\n",
    "    model = None\n",
    "    model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = resnet50tl(input_shape, numclasses, 'softmax')\n",
    "lr = 1e-5\n",
    "decay = 1e-7 #0.0\n",
    "optimizer = RMSprop(lr=lr, decay=decay)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "start_time = time.time()\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "print(\"processed time: {:.2f} sec\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluation\n",
    "\n",
    "Plot loss/val loss and loss/acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "training_acc = history.history['acc']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "fig=plt.figure(figsize=(12, 4))\n",
    "# Visualize loss history\n",
    "fig.add_subplot(121)\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, training_acc, 'b-')\n",
    "plt.legend(['Training Loss', 'Training Accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss/Acc')\n",
    "\n",
    "# Get training and test loss histories\n",
    "val_acc = history.history['val_acc']\n",
    "training_acc = history.history['acc']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(val_acc) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "fig.add_subplot(122)\n",
    "plt.plot(epoch_count, val_acc, 'r--')\n",
    "plt.plot(epoch_count, training_acc, 'b-')\n",
    "plt.legend(['Validation Accuracy', 'Training Accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.show();\n",
    "score = model.evaluate_generator(validation_generator)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save and load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "savemodel = '../models/celebriytag_model.h5'\n",
    "saveweight =  '../models/celebriytag_weight.h5'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# save model - ~400 MB\n",
    "model.save(savemodel)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# save weight only - ~200 MB\n",
    "model.save_weights(saveweight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = load_model(savemodel)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# load weight\n",
    "img_width, img_height = 200, 200\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "numclasses = 5\n",
    "model = resnet50tl(input_shape, numclasses, 'softmax')\n",
    "model.load_weights(saveweight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "import requests\n",
    "import os\n",
    "import http\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = ['ben_afflek',  'elton_john',  'jerry_seinfeld',  'madonna',  'mindy_kaling']\n",
    "validation_data_dir = '../datasets/celebrity/val'\n",
    "test_imgs = ['ben_afflek/httpabsolumentgratuitfreefrimagesbenaffleckjpg.jpg', 'madonna/httpcdnfuncheapcomwpcontentuploadsVOGUEjpg.jpg']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_img = os.path.join(validation_data_dir, test)\n",
    "img = image.load_img(test_img, target_size=(img_width, img_height))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x /= 255.\n",
    "classes = model.predict(x)\n",
    "result = np.squeeze(classes)\n",
    "result_indices = np.argmax(result)\n",
    "\n",
    "img = cv2.imread(test_img, cv2.IMREAD_COLOR)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.axis('off')\n",
    "plt.title(\"{}, {:.2f}%\".format(labels[result_indices], result[result_indices]*100))\n",
    "\n",
    "plt.imshow(img)\n",
    "\n",
    "#print(\"{}, {:.2f}%\".format(labels[result_indices], result[result_indices]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for test in test_imgs:\n",
    "    start_time = time.time()\n",
    "    test_img = os.path.join(validation_data_dir, test)\n",
    "    img = image.load_img(test_img, target_size=(img_width, img_height))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    print(x)\n",
    "    print(type(x), x.shape)\n",
    "    x /= 255.\n",
    "    classes = model.predict(x)\n",
    "    result = np.squeeze(classes)\n",
    "    result_indices = np.argmax(result)\n",
    "    \n",
    "    img = cv2.imread(test_img, cv2.IMREAD_COLOR)\n",
    "    img = cv2.resize(img, (img_width, img_height), interpolation = cv2.INTER_AREA)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    pilimg = Image.fromarray(img)\n",
    "    display(pilimg)\n",
    "    print(\"{}, {:.2f}%\".format(labels[result_indices], result[result_indices]*100))\n",
    "    print(\"processed time: {:.2f} sec\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import appface\n",
    "import appconfig\n",
    "\n",
    "test_urls =[\"http://www.cheatsheet.com/wp-content/uploads/2017/06/ben-affleck-jennifer-lopez.jpg\",\n",
    "            \"http://energy106.ca/wp-content/uploads/2017/09/160825140941-madonna-super-tease.jpg\", \n",
    "            \"http://cdn01.cdn.justjared.com/wp-content/uploads/headlines/2017/09/madonna-people.jpg\"]\n",
    "\n",
    "for test_url in test_urls:\n",
    "    r = requests.get(test_url)\n",
    "    img = Image.open(BytesIO(r.content))\n",
    "    img = np.array(img)\n",
    "    \n",
    "    rects, dt = appface.detectFaceCV(img)\n",
    "    print(\"img detect time: {:.2f}\".format(dt))\n",
    "\n",
    "    faces = []\n",
    "    i = 0\n",
    "    for rect in rects:\n",
    "        ps_time = time.time()\n",
    "\n",
    "        (x, y, w, h) = rect\n",
    "        roi_face = img[y:y+h, x:x+w]\n",
    "        roi_face = cv2.cvtColor(roi_face, cv2.COLOR_BGR2RGB)\n",
    "        i, conf = appface.classifyFace(model, roi_face)\n",
    "        \n",
    "        tag = appconfig.labels[i]\n",
    "\n",
    "        # be aware that convert numpy.int32 to int for json serialization\n",
    "        drect = { 'x': int(x), 'y': int(y), 'w': int(w), 'h': int(h) }\n",
    "        face = { 'tag': tag, 'confidence': conf, 'rect': drect }\n",
    "        faces.append(face)\n",
    "\n",
    "        print(\"{}:{:.2f}, recognition time:  {:.2f} sec\".format(tag, conf, time.time() - ps_time))\n",
    "        \n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        cv2.putText(img, \"{}:{:.2f}\".format(tag, conf), (x, y), 2, 1, (255,0,0), 1)\n",
    "        \n",
    "    pilimg = Image.fromarray(img)\n",
    "    display(pilimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with Customvision.ai\n",
    "\n",
    "You need to create a new project and train your model first.\n",
    "\n",
    "Then update project `api_id`, `api_iter` and `api_key` in `appconfig.py` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import appconfig\n",
    "#print(appconfig.api_id, appconfig.api_key, appconfig.api_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http POST request with binary data - Azure custom.ai prediction api\n",
    "\n",
    "for test in test_imgs:\n",
    "    start_time = time.time()\n",
    "    test_img = os.path.join(validation_data_dir, test)\n",
    "    img = cv2.imread(test_img, cv2.IMREAD_COLOR)\n",
    "    img = cv2.resize(img, (img_width, img_height), interpolation = cv2.INTER_AREA)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    pilimg = Image.fromarray(img)\n",
    "    display(pilimg)\n",
    "\n",
    "    apiurl = 'https://southcentralus.api.cognitive.microsoft.com/customvision/v2.0/Prediction/%s/image?iterationId=%s'\n",
    "    headers = {\"Content-Type\": \"application/octet-stream\", \"Prediction-Key\": appconfig.api_key }\n",
    "\n",
    "    with open(test_img, 'rb') as roi:\n",
    "        r = requests.post(apiurl % (appconfig.api_id, appconfig.api_iter), headers=headers, data=roi)\n",
    "\n",
    "        if (r.status_code == 200):\n",
    "\n",
    "            # JSON parse\n",
    "            pred = json.loads(r.content.decode(\"utf-8\"))\n",
    "\n",
    "            conf = float(pred['predictions'][0]['probability'])\n",
    "            label = pred['predictions'][0]['tagName']\n",
    "\n",
    "            print(\"{}, {:.2f}%\".format(label, conf*100))\n",
    "            print(\"processed time: {:.2f} sec\".format(time.time() - start_time))\n",
    "        else:\n",
    "            print(\"%d error: %s\" % (r.status_code, r.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continous learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Upload model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savemodel = '../models/facetag_model.h5'\n",
    "#print(appconfig.blobacct, appconfig.blobkey)\n",
    "\n",
    "call([\"blobxfer\", \"upload\", \"--storage-account\", appconfig.blobacct, \"--storage-account-key\", appconfig.blobkey, \n",
    "      \"--remote-path\", remotepath, \"--local-path\", savemodel, \"--skip-on-lmt-ge\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Retraining with new dataset\n",
    "\n",
    "Get a new face dataset\n",
    "\n",
    "#### Trigger new dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facetag_url = \"dsvm.iljoong.xyz:8080\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "import appconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesince = \"2018-07-23 00:00:01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigger new dataset\n",
    "headers = {\"Content-Type\": \"application/json\" }\n",
    "jobapi = \"http://%s/api/admin/job\" % facetag_url\n",
    "\n",
    "r = requests.post(jobapi, headers=headers, data=json.dumps({\"timesince\": timesince}))\n",
    "if (r.status_code == 201):\n",
    "    j = r.json()\n",
    "    blobpath = j['blobpath']\n",
    "    remotepath = blobpath.replace(\"https://%s.blob.core.windows.net/\" % appconfig.blobacct, \"\")\n",
    "    print(remotepath)\n",
    "else:\n",
    "    print('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### download dataset\n",
    "\n",
    "__note__: download after blob dataset is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "localpath='../../datasets'\n",
    "#print(appconfig.blobacct, appconfig.blobkey)\n",
    "\n",
    "call([\"blobxfer\", \"download\", \"--storage-account\", appconfig.blobacct, \"--storage-account-key\", appconfig.blobkey, \n",
    "      \"--remote-path\", remotepath, \"--local-path\", localpath, \n",
    "      \"--skip-on-lmt-ge\", \"--strip-components\", \"100\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-train\n",
    "\n",
    "1. re-organize the dataset after downloading a new zipfile from blob storage\n",
    "2. re-train model for improving face recoginition\n",
    "3. upload new model file to blob storage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### restart application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigger new dataset\n",
    "headers = {\"Content-Type\": \"application/json\" }\n",
    "jobapi = \"http://%s/api/admin/model\" % facetag_url\n",
    "\n",
    "r = requests.put(jobapi, headers=headers)\n",
    "if (r.status_code == 200):\n",
    "    print(r.text)\n",
    "else:\n",
    "    print('error')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
